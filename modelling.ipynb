{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare dataset from others sources than audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "columns = ['patient_id','audio_id', 'diagnose', 'audio_file', 'spectrogram_file','samsung','iphone','split_number','split_qty','less_A1097']\n",
    "df_ = pd.DataFrame(columns=columns)\n",
    "\n",
    "spectrograms_folder = 'audio_preparation/spectrograms'\n",
    "diagnose_dir = 'diagnose/'\n",
    "audios_features_folder = 'audios_features/'\n",
    "\n",
    "list_subdirs = os.listdir(spectrograms_folder)\n",
    "s=0\n",
    "for i in list_subdirs:\n",
    "    directory = spectrograms_folder+'/'+i+'/'\n",
    "    list_jpg = glob.glob(directory+\"*.png\")\n",
    "    if list_jpg:\n",
    "        for k in range(len(list_jpg)):\n",
    "            s+=1\n",
    "            spectrogram_file = list_jpg[k].split('/')[-1]\n",
    "            patient_id = spectrogram_file.split('_')[0]\n",
    "            if int(patient_id.split('A')[-1])<1098:\n",
    "                less_A1097 = 1\n",
    "            else:\n",
    "                less_A1097 = 0\n",
    "            #\n",
    "            if len(spectrogram_file.split('.')[0].split('_')[-1].split('s'))>1:\n",
    "                samsung = 1\n",
    "                iphone = 0\n",
    "                audio_file = spectrogram_file.split('.')[0].split('_')[1]+'_'+spectrogram_file.split('.')[0].split('_')[2]+'.wav'\n",
    "                audio_id = 'audio'+'_'+spectrogram_file.split('.')[0].split('_')[2]\n",
    "                split_number = spectrogram_file.split('.')[0].split('_')[1].split('a')[0]\n",
    "            elif len(spectrogram_file.split('.')[0].split('_')[-1].split('i'))>1:\n",
    "                samsung = 0\n",
    "                iphone = 1\n",
    "                audio_file = spectrogram_file.split('.')[0].split('_')[1]+'_'+spectrogram_file.split('.')[0].split('_')[2]+'.wav'\n",
    "                audio_id = 'audio'+'_'+spectrogram_file.split('.')[0].split('_')[2]\n",
    "                split_number = spectrogram_file.split('.')[0].split('_')[1].split('a')[0]\n",
    "            else:\n",
    "                samsung = 0\n",
    "                iphone = 0\n",
    "                audio_file = spectrogram_file.split('.')[0].split('_')[1]+'_'+spectrogram_file.split('.')[0].split('_')[2]+'.wav'\n",
    "                audio_id = 'audio'+'_'+spectrogram_file.split('.')[0].split('_')[2]\n",
    "                split_number = spectrogram_file.split('.')[0].split('_')[1].split('a')[0]\n",
    "            #\n",
    "            df_.loc[s] = np.array([patient_id,audio_id, np.NaN, audio_file, spectrogram_file,samsung,iphone,split_number,np.NaN,less_A1097])\n",
    "            patient_id\n",
    "            audio_id\n",
    "\n",
    "for patient_id in list(set(df_.patient_id)):\n",
    "    for audio_id in list(set(df_[(df_.patient_id==patient_id)].audio_id)):\n",
    "        dim = df_[(df_.patient_id==patient_id)&(df_.audio_id==audio_id)].shape[0]\n",
    "        df_.loc[(df_.patient_id==patient_id)&(df_.audio_id==audio_id), ['split_qty']] = dim\n",
    "\n",
    "\n",
    "#df_=pd.load(pandas_dir+pandas_file)\n",
    "\n",
    "\n",
    "diagnose_file = 'Diagnozes.csv'\n",
    "diagnose = pd.read_csv(diagnose_dir+diagnose_file,sep=';')\n",
    "\n",
    "\n",
    "\n",
    "# Assign spreadsheet filename to `file`\n",
    "file = diagnose_dir+'Diagnozes_2016.03.01.xlsx'\n",
    "#file = diagnose_dir+'Mano duomenys.xls'\n",
    "\n",
    "\n",
    "xl = pd.ExcelFile(file)\n",
    "#diagnose = xl.parse('Data')\n",
    "\n",
    "# Print the sheet names\n",
    "#print(xl.sheet_names)\n",
    "\n",
    "diagnose = xl.parse('Sheet1')\n",
    "\n",
    "diagnose = diagnose.rename(columns = {'File':'patient_id'})\n",
    "diagnose = diagnose.rename(columns = {'Dgn.':'sub_diagnose'})\n",
    "\n",
    "\n",
    "df_1 = pd.merge(df_, diagnose, how='left', on=['patient_id'])\n",
    "df_1.loc[(df_1.sub_diagnose==3), ['diagnose']] = 1\n",
    "df_1.loc[(df_1.sub_diagnose!=3), ['diagnose']] = 0\n",
    "\n",
    "df_ = df_1\n",
    "\n",
    "if not os.path.exists(audios_features_folder):\n",
    "    os.makedirs(audios_features_folder)\n",
    "\n",
    "df_.to_pickle(audios_features_folder+'target_data.p') \n",
    "#df_ = pd.read_pickle(audios_features_folder+'target_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup modelling environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Required parameters for modelling\n",
    "audio_record_devices_for_training = ['saumsung','iphone','studio']\n",
    "\n",
    "audio_record_devices_for_validating = ['iphone']\n",
    "\n",
    "audio_features = ['spectrogram','power_spectrum','soundnet','patient_survey']\n",
    "\n",
    "features_reduction_algorithm = ['PCA']\n",
    "\n",
    "features_after_reduction_size = 30\n",
    "\n",
    "prediction_algorithms = ['SVM','RandomForest','ELM','KNN']\n",
    "\n",
    "target = ['sick_healthy','all_diseases']\n",
    "\n",
    "sick_percentage_in_sample = 0.5\n",
    "\n",
    "sample_for_training_percentage = 0.6\n",
    "\n",
    "max_records_from_one_track = 20\n",
    "\n",
    "max_tracks_from_one_person = 20\n",
    "\n",
    "\n",
    "\n",
    "#Optional parameters\n",
    "\n",
    "soundnet_layers = [23,25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter by device records\n",
    "target_data = pd.DataFrame()\n",
    "\n",
    "if ('samsung' in audio_record_devices):\n",
    "    target_data = target_data.append(df_[df_.samsung == '1'], ignore_index = True)\n",
    "\n",
    "if ('iphone' in audio_record_devices):\n",
    "    target_data = target_data.append(df_[df_.iphone == '1'], ignore_index = True)\n",
    "\n",
    "if ('studio' in audio_record_devices):\n",
    "    target_data = target_data.append(df_[(df_.samsung == '0') & (df_.iphone == '0')], ignore_index = True)\n",
    "\n",
    "\n",
    "#Split to training, testing and validation datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "patient_id_train, patient_id_test_temp = train_test_split(target_data.patient_id.unique().tolist(), train_size = sample_for_training_percentage)\n",
    "patient_id_test, patient_id_validate = train_test_split(patient_id_test_temp, train_size = 0.5)\n",
    "\n",
    "\n",
    "target_data.loc[df_.patient_id.isin(patient_id_train),'patient_split'] = 'training'\n",
    "target_data.loc[df_.patient_id.isin(patient_id_test),'patient_split'] = 'testing'\n",
    "target_data.loc[df_.patient_id.isin(patient_id_validate),'patient_split'] = 'validating'\n",
    "\n",
    "target_data[(target_data.patient_split=='validating')&(target_data.iphone=='1')].groupby(['patient_id']).max().groupby(['diagnose']).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "\n",
    "\n",
    "audios_features_folder = 'audios_features'\n",
    "#import features extracted from spectrograms\n",
    "features_from_spectrograms = pickle.load( open( audios_features_folder+\"/\"+\"audios_features.p\", \"rb\" ) )\n",
    "\n",
    "\n",
    "#import features extracted from spectrograms\n",
    "features_from_power_spectrum = pickle.load( open( audios_features_folder+\"/\"+\"audios_features_power_spectrum.p\", \"rb\" ) )\n",
    "\n",
    "\n",
    "#Get data for training\n",
    "patient_id_train = target_data[target_data.patient_split=='training'].patient_id.unique().tolist()\n",
    "\n",
    "target_data[target_data.patient_id=='A1475'].audio_id.unique()\n",
    "\n",
    "\n",
    "train_x_dataset = []\n",
    "train_y_dataset = []\n",
    "for patien_id in patient_id_train:\n",
    "    audio_tracks = target_data[target_data.patient_id==patien_id].audio_id.unique()\n",
    "    selected_audio_tracks = random.sample(audio_tracks, min(audio_tracks.__len__(),max_tracks_from_one_person))\n",
    "    \n",
    "    for audio_track in selected_audio_tracks:\n",
    "        spectrogram_files = target_data[(target_data.patient_id==patien_id)&(target_data.audio_id==audio_track)].spectrogram_file.unique()\n",
    "        selected_spectrograms_from_track = random.sample(spectrogram_files, min(spectrogram_files.__len__(),max_records_from_one_track))\n",
    "        \n",
    "        if 'spectrogram' in audio_features:\n",
    "            \n",
    "        \n",
    "        if 'power_spectrum' in audio_features:\n",
    "            \n",
    "        \n",
    "        if 'soundnet' in audio_features:\n",
    "            \n",
    "            \n",
    "        if 'patient_survey' in audio_features:\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        train_x.append(img)\n",
    "        \n",
    "\n",
    "#Get data for testing\n",
    "test_x_dataset = []\n",
    "test_y_dataset = []\n",
    "\n",
    "patient_id_test = target_data[target_data.patient_split=='testing'].patient_id.unique().tolist()\n",
    "\n",
    "#Get data for validating\n",
    "validate_x_dataset = []\n",
    "validate_y_dataset = []\n",
    "\n",
    "patient_id_validate = target_data[target_data.patient_split=='validating'].patient_id.unique().tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
