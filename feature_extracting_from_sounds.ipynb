{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Features extracting from audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create spectogram for each audio file and get features matrix from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed 100 people records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed 200 people records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed 300 people records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed 400 people records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed 500 people records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed 600 people records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed 700 people records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed 800 people records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed 900 people records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed 1000 people records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed 1100 people records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed 1200 people records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed 1300 people records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed 1400 people records\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import scipy.io.wavfile as wav\n",
    "import numpy as np\n",
    "import os.path\n",
    "from PIL import Image\n",
    "import pickle\n",
    "os.chdir('/Users/vidmantasbendikas/Documents/github/soundrecognition')\n",
    "audio_folder = 'audio_preparation/Audio_splitted'\n",
    "spectrograms_folder = 'audio_preparation/spectrograms'\n",
    "audios_features_folder = 'audios_features'\n",
    "LOG_EVERY_N = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(spectrograms_folder):\n",
    "    os.makedirs(spectrograms_folder)\n",
    "\n",
    "\n",
    "list_subdirs = os.listdir(audio_folder)\n",
    "s=0\n",
    "for i in list_subdirs:\n",
    "    s += 1\n",
    "    if (s % LOG_EVERY_N) == 0:\n",
    "        print \"Preprocessed \"+str(s)+\" people records\"  \n",
    "    directory = audio_folder+'/'+i+'/'\n",
    "    new_directory = spectrograms_folder+'/'+i+'/'\n",
    "    if not os.path.exists(new_directory):\n",
    "        os.makedirs(new_directory)\n",
    "    #\n",
    "    list_wav = glob.glob(directory+\"*.wav\")\n",
    "    for k in range(len(list_wav)):\n",
    "        spectrogram_dir = spectrograms_folder+'/'+i+'/'+ i+'_'+list_wav[k].split('/')[-1].split('.')[0]+'.png'\n",
    "        #command = \"sox \"+list_wav[k]+\" -n spectrogram -l -r -o \"+spectrogram_dir\n",
    "        command = \"sox \"+list_wav[k]+\" -n spectrogram -l -m -r -w Kaiser -o \"+spectrogram_dir\n",
    "        os.system(command)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform spectrogram image into matrix and save it to tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed 100 spectrograms into array\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed 200 spectrograms into array\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed 300 spectrograms into array\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed 400 spectrograms into array\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed 500 spectrograms into array\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed 600 spectrograms into array\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed 700 spectrograms into array\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed 800 spectrograms into array\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed 900 spectrograms into array\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed 1000 spectrograms into array\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed 1100 spectrograms into array\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed 1200 spectrograms into array\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed 1300 spectrograms into array\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed 1400 spectrograms into array\n"
     ]
    }
   ],
   "source": [
    "def img_to_matrix(filename, verbose=False, STANDARD_SIZE= (120,120)):\n",
    "    \"\"\"\n",
    "    takes a filename and turns it into a numpy array of RGB pixels\n",
    "    \"\"\"\n",
    "    img = Image.open(filename)\n",
    "    if verbose==True:\n",
    "        print \"changing size from %s to %s\" % (str(img.size), str(STANDARD_SIZE))\n",
    "    img = img.resize(STANDARD_SIZE)\n",
    "    img = list(img.getdata())\n",
    "    img = np.array(img)\n",
    "    return img\n",
    "\n",
    "spectograms_subfolders = os.listdir(spectrograms_folder)\n",
    "audios_features = {}\n",
    "s = 0\n",
    "for subfolder in spectograms_subfolders:\n",
    "    s += 1\n",
    "    if (s % LOG_EVERY_N) == 0:\n",
    "        print \"Transformed \"+str(s)+\" spectrograms into array\"  \n",
    "    path_to_spectograms_files = spectrograms_folder+'/'+subfolder+'/'\n",
    "    spectrograms_files_list = glob.glob(path_to_spectograms_files+\"*.png\")\n",
    "    \n",
    "    audios_features[subfolder] = {}\n",
    "    audios_features[subfolder]['device'] = {}\n",
    "    audios_features[subfolder]['device']['studio'] = {}\n",
    "    audios_features[subfolder]['device']['iphone'] = {}\n",
    "    audios_features[subfolder]['device']['samsung'] = {}\n",
    "    for spectrogram_file in spectrograms_files_list:\n",
    "        if spectrogram_file.split('_')[-1].split('a')[0]=='s':\n",
    "            audio_features = img_to_matrix(spectrogram_file)\n",
    "            audios_features[subfolder]['device']['samsung'][spectrogram_file.split('/')[-1]] = {}\n",
    "            audios_features[subfolder]['device']['samsung'][spectrogram_file.split('/')[-1]]['features'] = {}\n",
    "            audios_features[subfolder]['device']['samsung'][spectrogram_file.split('/')[-1]]['features']['spectrogram'] = audio_features\n",
    "       \n",
    "        elif spectrogram_file.split('_')[-1].split('a')[0]=='i':\n",
    "            audio_features = img_to_matrix(spectrogram_file)\n",
    "            audios_features[subfolder]['device']['iphone'][spectrogram_file.split('/')[-1]] = {}\n",
    "            audios_features[subfolder]['device']['iphone'][spectrogram_file.split('/')[-1]]['features'] = {}\n",
    "            audios_features[subfolder]['device']['iphone'][spectrogram_file.split('/')[-1]]['features']['spectrogram'] = audio_features \n",
    "        else:\n",
    "            audio_features = img_to_matrix(spectrogram_file)\n",
    "            audios_features[subfolder]['device']['studio'][spectrogram_file.split('/')[-1]] = {}\n",
    "            audios_features[subfolder]['device']['studio'][spectrogram_file.split('/')[-1]]['features'] = {}\n",
    "            audios_features[subfolder]['device']['studio'][spectrogram_file.split('/')[-1]]['features']['spectrogram'] = audio_features\n",
    "\n",
    "if not os.path.exists(audios_features_folder):\n",
    "    os.makedirs(audios_features_folder)\n",
    "\n",
    "pickle.dump(audios_features, open(audios_features_folder+\"/\"+\"audios_features.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract features from audio using soundnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"python extract_feat.py -m 24 -x 25 -s -p extract -t data.txt\"\n",
    "os.system(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The power spectrum of each segment can be obtained by applying the Fourier transform, which converts the waveform data from the time domain to the frequency domain. The code below demonstrates how to use NumPyâ€™s Fourier transform module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_recording(recording, segment_length, sample_rate):\n",
    "    segments = []\n",
    "    index = 0\n",
    "    while index < len(recording):\n",
    "        segment = recording[index:int(index + segment_length*sample_rate)]\n",
    "        segments.append(segment)\n",
    "        index += segment_length*sample_rate\n",
    "    return segments\n",
    "\n",
    "def calculate_normalized_power_spectrum(recording, sample_rate):\n",
    "    # np.fft.fft returns the discrete fourier transform of the recording\n",
    "    fft = np.fft.fft(recording)\n",
    "    number_of_samples = len(recording)\n",
    "    # sample_length is the length of each sample in seconds\n",
    "    sample_length = 1./sample_rate\n",
    "    # fftfreq is a convenience function which returns the list of frequencies measured by the fft\n",
    "    frequencies = np.fft.fftfreq(number_of_samples, sample_length)\n",
    "    positive_frequency_indices = np.where(frequencies>0)\n",
    "    # positive frequences returned by the fft\n",
    "    frequencies = frequencies[positive_frequency_indices]\n",
    "    # magnitudes of each positive frequency in the recording\n",
    "    magnitudes = abs(fft[positive_frequency_indices])\n",
    "    # some segments are louder than others, so normalize each segment\n",
    "    magnitudes = magnitudes / np.linalg.norm(magnitudes)\n",
    "    return frequencies, magnitudes\n",
    "\n",
    "def create_power_spectra_array(segment_length, sample_rate):\n",
    "    number_of_samples_per_segment = int(segment_length * sample_rate)\n",
    "    time_per_sample = 1./sample_rate\n",
    "    frequencies = np.fft.fftfreq(number_of_samples_per_segment, time_per_sample)\n",
    "    positive_frequencies = frequencies[frequencies>0]\n",
    "    power_spectra_array = np.empty((0, len(positive_frequencies)))\n",
    "    return power_spectra_array\n",
    "\n",
    "def fill_power_spectra_array(splits, power_spectra_array, fs):\n",
    "    filled_array = power_spectra_array\n",
    "    for segment in splits:\n",
    "        freqs, mags = calculate_normalized_power_spectrum(segment, fs)\n",
    "        filled_array = np.vstack((filled_array, mags))\n",
    "    return filled_array\n",
    "\n",
    "\n",
    "# wav.read returns the sample_rate and a numpy array containing each audio sample from the .wav file\n",
    "#sample_rate, recording = wav.read(filename)\n",
    "segment_length = 1 # length in seconds\n",
    "#segments = split_recording(recording, segment_length, sample_rate)\n",
    "#power_spectra_array = create_power_spectra_array(segment_length,sample_rate)\n",
    "#power_spectra_array = fill_power_spectra_array(segments, power_spectra_array, sample_rate)\n",
    "\n",
    "list_subfolders = os.listdir(audio_folder)\n",
    "audios_features = {}\n",
    "s = 0\n",
    "for subfolder in list_subfolders:\n",
    "    s += 1\n",
    "    if (s % LOG_EVERY_N) == 0:\n",
    "        print \"Transformed \"+str(s)+\" audio into power spectrum array\"  \n",
    "    path_to_wav_files = audio_folder+'/'+subfolder+'/'\n",
    "    wav_files_list = glob.glob(path_to_wav_files+\"*.wav\")\n",
    "    \n",
    "    audios_features[subfolder] = {}\n",
    "    audios_features[subfolder]['device'] = {}\n",
    "    audios_features[subfolder]['device']['studio'] = {}\n",
    "    audios_features[subfolder]['device']['iphone'] = {}\n",
    "    audios_features[subfolder]['device']['samsung'] = {}\n",
    "    for wav_file in wav_files_list:\n",
    "        sample_rate, recording = wav.read(wav_file)\n",
    "        segments = split_recording(recording, segment_length, sample_rate)\n",
    "        audio_features = create_power_spectra_array(segment_length,sample_rate)\n",
    "        audio_features = fill_power_spectra_array(segments, audio_features, sample_rate)\n",
    "        \n",
    "        if wav_file.split('_')[-1].split('a')[0]=='s':\n",
    "            audios_features[subfolder]['device']['samsung'][wav_file.split('/')[-1]] = {}\n",
    "            audios_features[subfolder]['device']['samsung'][wav_file.split('/')[-1]]['features'] = {}\n",
    "            audios_features[subfolder]['device']['samsung'][wav_file.split('/')[-1]]['features']['power_spectrum'] = audio_features[0]\n",
    "       \n",
    "        elif wav_file.split('_')[-1].split('a')[0]=='i':\n",
    "            audios_features[subfolder]['device']['iphone'][wav_file.split('/')[-1]] = {}\n",
    "            audios_features[subfolder]['device']['iphone'][wav_file.split('/')[-1]]['features'] = {}\n",
    "            audios_features[subfolder]['device']['iphone'][wav_file.split('/')[-1]]['features']['power_spectrum'] = audio_features[0] \n",
    "        else:\n",
    "            audios_features[subfolder]['device']['studio'][wav_file.split('/')[-1]] = {}\n",
    "            audios_features[subfolder]['device']['studio'][wav_file.split('/')[-1]]['features'] = {}\n",
    "            audios_features[subfolder]['device']['studio'][wav_file.split('/')[-1]]['features']['power_spectrum'] = audio_features[0]\n",
    "\n",
    "if not os.path.exists(audios_features_folder):\n",
    "    os.makedirs(audios_features_folder)\n",
    "\n",
    "pickle.dump(audios_features, open(audios_features_folder+\"/\"+\"audios_features_power_spectrum.p\", \"wb\" ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
